{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0fe8602",
   "metadata": {},
   "source": [
    "# Pandas Essentials\n",
    "As models need a interface to read and understand the data, Pandas is a python package, which is used for data manipulation and exploratory data analysis before we submit the data for the model training. Its ability to read from and write to an extensive list of formats makes it a versatile tool for data science practitioners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc6a07",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- [Python3/tutorial](https://docs.python.org/3/tutorial/introduction.html)\n",
    "- [Pandas-10min-guide](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "- [essential-pandas-functions](https://medium.com/@hkanjanv/essential-pandas-functions-for-data-science-and-machine-learning-in-python-a-practical-guide-6c7df033d6f6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f3e25d",
   "metadata": {},
   "source": [
    "## Goal\n",
    "- setup and load data using pandas.\n",
    "- data selection and update.\n",
    "- handling missing data.\n",
    "- save processed data to file.\n",
    "- import data from file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd585942",
   "metadata": {},
   "source": [
    "## Setup and load data using pandas\n",
    "### Importing the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69321d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93088f7",
   "metadata": {},
   "source": [
    "### Create a Panda Series,Data Frame\n",
    "Pandas provides two types of classes for handling data:\n",
    "- Series: a one-dimensional labeled array holding data of any type such as integers, strings, Python objects etc.\n",
    "- DataFrame: a two-dimensional data structure that holds data like a two-dimension array or a table with rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2bab01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    3.0\n",
      "2    5.0\n",
      "3    NaN\n",
      "4    6.0\n",
      "5    8.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Series\n",
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "42a2c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D\n",
      "2023-01-01 -0.869058 -0.447785  0.280211 -0.045918\n",
      "2023-01-02 -0.092181  1.527722  1.080601  0.557053\n",
      "2023-01-03 -0.601719  1.098997  1.869991  0.571191\n",
      "2023-01-04  0.401115 -0.731362 -0.626753  2.199811\n",
      "2023-01-05  0.699923 -2.314103  2.045064 -0.076148\n",
      "2023-01-06  0.620450  0.954470 -1.577435 -0.138895\n"
     ]
    }
   ],
   "source": [
    "## DataFrame\n",
    "dates = pd.date_range(\"20230101\", periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\"ABCD\"))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc883e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a DataFrame by passing a dictionary of objects where the keys are the \n",
    "## column labels and the values are the column values.\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": 1.0,\n",
    "        \"B\": pd.Timestamp(\"20230102\"),\n",
    "        \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n",
    "        \"D\": np.array([3] * 4, dtype=\"int32\"),\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "        \"F\": \"foo\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e8107a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A          float64\n",
      "B    datetime64[s]\n",
      "C          float32\n",
      "D            int32\n",
      "E         category\n",
      "F           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## DataFrame Column Types\n",
    "print(df2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f767c36",
   "metadata": {},
   "source": [
    "## Viewing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab871b29",
   "metadata": {},
   "source": [
    "### Basic functions\n",
    "- df.head, for first n records.\n",
    "- df.tail, for last n records.\n",
    "- df.index, show the current index list of the data frame.\n",
    "- df.columns, shows the current columns of the data frame.\n",
    "- df.describe, shows a quick statistic summary of the data.\n",
    "- df.T, to re-orient or transpose the data frame.\n",
    "- df.sort_index, to sort the data frame by index.\n",
    "- df.sort_by_value, to sort the data frame by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5d95bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head ====================\n",
      "     A          B    C  D      E    F\n",
      "0  1.0 2023-01-02  1.0  3   test  foo\n",
      "1  1.0 2023-01-02  1.0  3  train  foo\n",
      "Tail ====================\n",
      "     A          B    C  D      E    F\n",
      "1  1.0 2023-01-02  1.0  3  train  foo\n",
      "2  1.0 2023-01-02  1.0  3   test  foo\n",
      "3  1.0 2023-01-02  1.0  3  train  foo\n",
      "Index ====================\n",
      "Index([0, 1, 2, 3], dtype='int64')\n",
      "Columns ====================\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')\n",
      "Numpy ====================\n",
      "[[1.0 Timestamp('2023-01-02 00:00:00') 1.0 3 'test' 'foo']\n",
      " [1.0 Timestamp('2023-01-02 00:00:00') 1.0 3 'train' 'foo']\n",
      " [1.0 Timestamp('2023-01-02 00:00:00') 1.0 3 'test' 'foo']\n",
      " [1.0 Timestamp('2023-01-02 00:00:00') 1.0 3 'train' 'foo']]\n",
      "Describe ====================\n",
      "         A                    B    C    D\n",
      "count  4.0                    4  4.0  4.0\n",
      "mean   1.0  2023-01-02 00:00:00  1.0  3.0\n",
      "min    1.0  2023-01-02 00:00:00  1.0  3.0\n",
      "25%    1.0  2023-01-02 00:00:00  1.0  3.0\n",
      "50%    1.0  2023-01-02 00:00:00  1.0  3.0\n",
      "75%    1.0  2023-01-02 00:00:00  1.0  3.0\n",
      "max    1.0  2023-01-02 00:00:00  1.0  3.0\n",
      "std    0.0                  NaN  0.0  0.0\n",
      "Transpose ====================\n",
      "                     0                    1                    2  \\\n",
      "A                  1.0                  1.0                  1.0   \n",
      "B  2023-01-02 00:00:00  2023-01-02 00:00:00  2023-01-02 00:00:00   \n",
      "C                  1.0                  1.0                  1.0   \n",
      "D                    3                    3                    3   \n",
      "E                 test                train                 test   \n",
      "F                  foo                  foo                  foo   \n",
      "\n",
      "                     3  \n",
      "A                  1.0  \n",
      "B  2023-01-02 00:00:00  \n",
      "C                  1.0  \n",
      "D                    3  \n",
      "E                train  \n",
      "F                  foo  \n",
      "Sort by Axis ====================\n",
      "     F      E  D    C          B    A\n",
      "0  foo   test  3  1.0 2023-01-02  1.0\n",
      "1  foo  train  3  1.0 2023-01-02  1.0\n",
      "2  foo   test  3  1.0 2023-01-02  1.0\n",
      "3  foo  train  3  1.0 2023-01-02  1.0\n",
      "Sort by Values ====================\n",
      "     A          B    C  D      E    F\n",
      "0  1.0 2023-01-02  1.0  3   test  foo\n",
      "1  1.0 2023-01-02  1.0  3  train  foo\n",
      "2  1.0 2023-01-02  1.0  3   test  foo\n",
      "3  1.0 2023-01-02  1.0  3  train  foo\n"
     ]
    }
   ],
   "source": [
    "## DataFrame First and Last Rows\n",
    "print('Head ====================')\n",
    "print(df2.head(2))\n",
    "print('Tail ====================')\n",
    "print(df2.tail(3))\n",
    "print('Index ====================')\n",
    "print(df2.index)\n",
    "print('Columns ====================')\n",
    "print(df2.columns)\n",
    "print('Numpy ====================')\n",
    "print(df2.to_numpy())\n",
    "print('Describe ====================')\n",
    "print(df2.describe())\n",
    "print('Transpose ====================')\n",
    "print(df2.T)\n",
    "print('Sort by Axis ====================')\n",
    "print(df2.sort_index(axis=1, ascending=False))\n",
    "print('Sort by Values ====================')\n",
    "print(df2.sort_values(by=\"B\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7780b592",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46bdf8",
   "metadata": {},
   "source": [
    "### Selecting data by using []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "28a6bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A          B    C  D      E    F\n",
      "0  1.0 2023-01-02  1.0  3   test  foo\n",
      "1  1.0 2023-01-02  1.0  3  train  foo\n",
      "1. =========================\n",
      "Index([0, 1, 2, 3], dtype='int64')\n",
      "2. =========================\n",
      "     A          B\n",
      "0  1.0 2023-01-02\n",
      "1  1.0 2023-01-02\n",
      "2  1.0 2023-01-02\n",
      "3  1.0 2023-01-02\n",
      "3. =========================\n",
      "     A          B\n",
      "0  1.0 2023-01-02\n",
      "1  1.0 2023-01-02\n",
      "2  1.0 2023-01-02\n",
      "4. =========================\n",
      "     A          B\n",
      "1  1.0 2023-01-02\n",
      "2  1.0 2023-01-02\n",
      "5. =========================\n",
      "     A          B    C  D      E    F\n",
      "0  1.0 2023-01-02  1.0  3   test  foo\n",
      "1  1.0 2023-01-02  1.0  3  train  foo\n",
      "2  1.0 2023-01-02  1.0  3   test  foo\n",
      "3  1.0 2023-01-02  1.0  3  train  foo\n"
     ]
    }
   ],
   "source": [
    "## Selection by rows with range query\n",
    "print(df2[0:2])\n",
    "## Selection by label\n",
    "print('1. =========================')\n",
    "print(df2.index)\n",
    "print('2. =========================')\n",
    "## Selecting all rows (:) with a select column labels:\n",
    "print(df2.loc[:, [\"A\", \"B\"]])\n",
    "print('3. =========================')\n",
    "## For label slicing, both endpoints are included:\n",
    "print(df2.loc[0:2, [\"A\", \"B\"]])\n",
    "print('4. =========================')\n",
    "## Selection by position\n",
    "print(df2.iloc[1:3, 0:2])\n",
    "print('5. =========================')\n",
    "## Boolean indexing\n",
    "print(df2[df2.A > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df772da2",
   "metadata": {},
   "source": [
    "### Selecting data using loc,iloc\n",
    "- In pandas, the loc and iloc indexers are used to select data from a DataFrame, with the key difference being that loc uses labels (row and column names), while iloc uses integer positions (0-based indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "01123db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "         Name  Age     City\n",
      "row1    Alice   25       NY\n",
      "row2      Bob   30       LA\n",
      "row3  Charlie   35  Chicago\n",
      "Data in data[row2][name] using loc\n",
      "Bob\n",
      "Using the loc\n",
      "         Name     City\n",
      "row1    Alice       NY\n",
      "row2      Bob       LA\n",
      "row3  Charlie  Chicago\n",
      "Data in data[row2][name] using iloc\n",
      "Bob\n",
      "Using the iloc\n",
      "         Name  Age\n",
      "row1    Alice   25\n",
      "row2      Bob   30\n",
      "row3  Charlie   35\n"
     ]
    }
   ],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35], 'City': ['NY', 'LA', 'Chicago']}\n",
    "addr_df = pd.DataFrame(data, index=['row1', 'row2', 'row3'])\n",
    "\n",
    "print('DataFrame:')\n",
    "print(addr_df)\n",
    "\n",
    "# Select row with label 'row2' and column with label 'Name'\n",
    "print('Data in data[row2][name] using loc')\n",
    "print(addr_df.loc['row2', 'Name'])\n",
    "# Output: Bob\n",
    "\n",
    "# Select all rows from label 'row1' to 'row3' (inclusive) and specific columns by label\n",
    "print('Using the loc')\n",
    "print(addr_df.loc['row1':'row3', ['Name', 'City']])\n",
    "\n",
    "# Assuming the same DataFrame 'addr_df' as above\n",
    "# Select the second row (position 1) and the first column (position 0)\n",
    "print('Data in data[row2][name] using iloc')\n",
    "print(addr_df.iloc[1, 0])\n",
    "# Output: Bob\n",
    "\n",
    "# Select the first three rows (positions 0, 1, 2) and the first two columns (positions 0, 1)\n",
    "print('Using the iloc')\n",
    "print(addr_df.iloc[0:3, 0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530fe251",
   "metadata": {},
   "source": [
    "### Selection by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0627a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Name    Alice\n",
      "Age        25\n",
      "City       NY\n",
      "Name: row1, dtype: object\n",
      "==========================\n",
      "         Name  Age\n",
      "row2      Bob   30\n",
      "row3  Charlie   35\n",
      "==========================\n",
      "      Age     City\n",
      "row1   25       NY\n",
      "row3   35  Chicago\n",
      "==========================\n",
      "         Name  Age     City\n",
      "row2      Bob   30       LA\n",
      "row3  Charlie   35  Chicago\n",
      "==========================\n",
      "         Name\n",
      "row1    Alice\n",
      "row2      Bob\n",
      "row3  Charlie\n"
     ]
    }
   ],
   "source": [
    "## Select a row\n",
    "print('==========================')\n",
    "print(addr_df.iloc[0])\n",
    "## Select multiple rows and columns\n",
    "print('==========================')\n",
    "print(addr_df.iloc[1:3, 0:2])\n",
    "## Lists of integer position locations:\n",
    "print('==========================')\n",
    "print(addr_df.iloc[[0, 2], [1, 2]])\n",
    "## Slicing rows and select all the columns:\n",
    "print('==========================')\n",
    "print(addr_df.iloc[1:3, :])\n",
    "## slicing columns explicitly\n",
    "print('==========================')\n",
    "print(addr_df.iloc[:, [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301dde09",
   "metadata": {},
   "source": [
    "### Selection by Boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cbf662ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  Age     City\n",
      "row2      Bob   30       LA\n",
      "row3  Charlie   35  Chicago\n",
      "==========================\n",
      "       Name  Age City\n",
      "row1  Alice   25   NY\n",
      "==========================\n",
      "         Name  Age     City\n",
      "row1    Alice   25       NY\n",
      "row3  Charlie   35  Chicago\n"
     ]
    }
   ],
   "source": [
    "## Select rows where df.A is greater than 0.\n",
    "print(addr_df[addr_df.Age > 25])\n",
    "print('==========================')\n",
    "## Selecting values from a DataFrame where a boolean condition is met:\n",
    "print(addr_df[addr_df['City'] == 'NY'])\n",
    "print('==========================')\n",
    "## Using isin() method for filtering\n",
    "print(addr_df[addr_df['City'].isin(['NY', 'Chicago'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d069f0",
   "metadata": {},
   "source": [
    "## Data Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "952ef728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  Age     City\n",
      "row1    Alice   25       NY\n",
      "row2      Bob   30       LA\n",
      "row3  Charlie   35  Chicago\n",
      "==========================\n",
      "         Name  Age     City Country\n",
      "row1    Alice   25       NY     USA\n",
      "row2      Bob   30       LA     USA\n",
      "row3  Charlie   35  Chicago     USA\n",
      "==========================\n",
      "         Name  Age     City Country\n",
      "row1    Alice   26       NY     USA\n",
      "row2      Bob   30       LA     USA\n",
      "row3  Charlie   35  Chicago     USA\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "print(addr_df)\n",
    "print('==========================')\n",
    "## Setting a new column automatically aligns the data by the indexes:\n",
    "addr_df['Country'] = ['USA', 'USA', 'USA']\n",
    "print(addr_df)\n",
    "print('==========================')\n",
    "## updating values in a DataFrame\n",
    "addr_df.loc[addr_df['Name'] == 'Alice', 'Age'] = 26\n",
    "print(addr_df)\n",
    "print('==========================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b698702",
   "metadata": {},
   "source": [
    "### Adding and Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "213d3e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  Age     City Country Profession\n",
      "row1    Alice   26       NY     USA   Engineer\n",
      "row2      Bob   30       LA     USA     Doctor\n",
      "row3  Charlie   35  Chicago     USA     Artist\n",
      "==========================\n",
      "         Name  Age     City Country Profession  Salary\n",
      "row1    Alice   26       NY     USA   Engineer   70000\n",
      "row2      Bob   30       LA     USA     Doctor  120000\n",
      "row3  Charlie   35  Chicago     USA     Artist   50000\n",
      "==========================\n",
      "         Name  Age     City Country Profession  Salary  Experience      Tax\n",
      "row1    Alice   26       NY     USA   Engineer   70000           3  14000.0\n",
      "row2      Bob   30       LA     USA     Doctor  120000           8  24000.0\n",
      "row3  Charlie   35  Chicago     USA     Artist   50000           5  10000.0\n",
      "==========================\n",
      "         Name  Age     City Country Profession  Salary  Experience\n",
      "row1    Alice   26       NY     USA   Engineer   70000           3\n",
      "row2      Bob   30       LA     USA     Doctor  120000           8\n",
      "row3  Charlie   35  Chicago     USA     Artist   50000           5\n",
      "==========================\n",
      "         Name  Age     City Country Profession    Salary  Experience\n",
      "row1    Alice   26       NY     USA   Engineer   70000.0           3\n",
      "row2      Bob   30       LA     USA     Doctor  132000.0           8\n",
      "row3  Charlie   35  Chicago     USA     Artist   55000.0           5\n",
      "==========================\n",
      "         Name  Age           City Country Profession    Salary  Experience\n",
      "row1    Alice   26  San Francisco     USA   Engineer   70000.0           3\n",
      "row2      Bob   30             LA     USA     Doctor  132000.0           8\n",
      "row3  Charlie   35        Chicago     USA     Artist   55000.0           5\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "### Add a new column\n",
    "addr_df['Profession'] = ['Engineer', 'Doctor', 'Artist']\n",
    "print(addr_df)\n",
    "print('==========================')\n",
    "### Add column - salary\n",
    "addr_df['Salary'] = [70000, 120000, 50000]\n",
    "print(addr_df)\n",
    "print('==========================')\n",
    "### Add column - Experience, Tax\n",
    "addr_df['Experience'] = [3, 8, 5]\n",
    "addr_df['Tax'] = addr_df['Salary'] * 0.2\n",
    "print(addr_df)\n",
    "print('==========================')\n",
    "### Drop a column Tax\n",
    "addr_df = addr_df.drop(columns=['Tax'])\n",
    "print(addr_df)\n",
    "print('==========================')\n",
    "## Increase Salary by 10% for experience greater than 5 years\n",
    "## change dtype of salary to float\n",
    "addr_df['Salary'] = addr_df['Salary'].astype(float)\n",
    "\n",
    "addr_df.loc[addr_df['Experience'] >= 5, 'Salary'] *= 1.1\n",
    "print(addr_df)\n",
    "print('==========================')\n",
    "## using at to update a single value\n",
    "addr_df.at['row1', 'City'] = 'San Francisco'\n",
    "print(addr_df)\n",
    "print('==========================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b2311",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "- the data is expected to have null or NAN values as part of it. From  NumPy data types, np.nan represents missing data.\n",
    "- we can either delete or replace data within a DataFrame to prepare it for a model, depending on the specific context, data type, and the expected outcome. This process is a crucial part of data cleaning and preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e4ee9c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with NaN values:\n",
      "     A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  2.0  2.0  NaN\n",
      "2  NaN  3.0  NaN\n",
      "Sum of NaN values in each column:\n",
      "A    1\n",
      "B    1\n",
      "C    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## DataFrame with missing values\n",
    "data_with_nan = {\n",
    "    'A': [1, 2, np.nan],\n",
    "    'B': [np.nan, 2, 3],\n",
    "    'C': [1, np.nan, np.nan]\n",
    "}\n",
    "df_with_nan = pd.DataFrame(data_with_nan)\n",
    "print('DataFrame with NaN values:')\n",
    "print(df_with_nan)\n",
    "## Sum of NaN values in each column\n",
    "print('Sum of NaN values in each column:')\n",
    "print(df_with_nan.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2db89f",
   "metadata": {},
   "source": [
    "### Handling Missing Data - By Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1c2992f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop rows with any NaN values:\n",
      "Sum of NaN values in each column:\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# Handling missing data\n",
    "print('Drop rows with any NaN values:')\n",
    "# print(df_with_nan.dropna())\n",
    "## Drop Null values in columns\n",
    "df_with_nan.dropna(axis=1,inplace=True)\n",
    "# print('Fill NaN values with 0:')\n",
    "# print(df_with_nan.fillna(0))\n",
    "print('Sum of NaN values in each column:')\n",
    "print(df_with_nan.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2e0f5",
   "metadata": {},
   "source": [
    "### Handling the missing data - By Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "92574b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with NaN values:\n",
      "     A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  2.0  2.0  NaN\n",
      "2  NaN  3.0  NaN\n",
      "DataFrame after filling NaN values with column means:\n",
      "     A    B    C\n",
      "0  1.0  2.5  1.0\n",
      "1  2.0  2.0  1.0\n",
      "2  1.5  3.0  1.0\n",
      "Sum of NaN values in each column after filling:\n",
      "A    0\n",
      "B    0\n",
      "C    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Handling the missing data - replace by mean\n",
    "data_with_nan = {\n",
    "    'A': [1, 2, np.nan],\n",
    "    'B': [np.nan, 2, 3],\n",
    "    'C': [1, np.nan, np.nan]\n",
    "}\n",
    "df_with_nan = pd.DataFrame(data_with_nan)\n",
    "print('DataFrame with NaN values:')\n",
    "print(df_with_nan)\n",
    "# Fill NaN values with the mean of each column\n",
    "df_filled = df_with_nan.fillna(df_with_nan.mean())\n",
    "print('DataFrame after filling NaN values with column means:')\n",
    "print(df_filled)\n",
    "## Verify no NaN values remain\n",
    "print('Sum of NaN values in each column after filling:')\n",
    "print(df_filled.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb9c0b",
   "metadata": {},
   "source": [
    "## Importing and exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d15f2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting data to CSV to a file.\n",
    "df_filled.to_csv(\"foo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1e77b628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported DataFrame from CSV:\n",
      "     A    B    C\n",
      "0  1.0  2.5  1.0\n",
      "1  2.0  2.0  1.0\n",
      "2  1.5  3.0  1.0\n"
     ]
    }
   ],
   "source": [
    "## Importin the exported CSV file\n",
    "imported_df = pd.read_csv(\"foo.csv\", index_col=0)\n",
    "print('Imported DataFrame from CSV:')\n",
    "print(imported_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7da94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
